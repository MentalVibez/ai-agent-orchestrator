# ============================================================
# AI Agent Orchestrator — Environment Configuration
# Copy this file to .env and fill in your values.
# ============================================================

# -----------------------------------------------------------
# LLM Provider Selection
# Options: bedrock | openai | ollama
# -----------------------------------------------------------
LLM_PROVIDER=bedrock

# -----------------------------------------------------------
# AWS Bedrock (used when LLM_PROVIDER=bedrock)
# -----------------------------------------------------------
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
LLM_MODEL=anthropic.claude-3-5-sonnet-20241022-v2:0

# -----------------------------------------------------------
# OpenAI (used when LLM_PROVIDER=openai)
# -----------------------------------------------------------
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o

# -----------------------------------------------------------
# Ollama — local/self-hosted (used when LLM_PROVIDER=ollama)
# -----------------------------------------------------------
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# -----------------------------------------------------------
# API Security
# -----------------------------------------------------------
API_KEY=change-me-in-production
REQUIRE_API_KEY=true
WEBHOOK_SECRET=

# -----------------------------------------------------------
# Database
# Leave blank to use the default path inside the Docker volume.
# Set to sqlite:///./orchestrator.db for local development.
# -----------------------------------------------------------
# DATABASE_URL=sqlite:///./orchestrator.db

# -----------------------------------------------------------
# Application
# -----------------------------------------------------------
DEBUG=false
LOG_LEVEL=INFO
HOST=0.0.0.0
PORT=8000
